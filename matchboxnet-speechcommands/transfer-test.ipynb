{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-03-25 03:25:28 experimental:28] Module <class 'nemo.collections.asr.models.clustering_diarizer.ClusteringDiarizer'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2021-03-25 03:25:28 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text_dali.AudioToCharDALIDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyaudio as pa\n",
    "import os, time\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample rate, Hz\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-03-25 03:26:14 cloud:66] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemospeechmodels/versions/1.0.0a5/files/MatchboxNet-3x1x64-v2-subset-task.nemo to /home/cjbayron/.cache/torch/NeMo/NeMo_1.0.0rc2/MatchboxNet-3x1x64-v2-subset-task/da747cb40572af6f3774d7e33841815c/MatchboxNet-3x1x64-v2-subset-task.nemo\n",
      "[NeMo I 2021-03-25 03:26:17 common:615] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-03-25 03:26:17 modelPT:133] Please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /media/smajumdar/data/Datasets/GSC_subset/google_speech_recognition_v2/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - 'yes'\n",
      "    - 'no'\n",
      "    - up\n",
      "    - down\n",
      "    - left\n",
      "    - right\n",
      "    - 'on'\n",
      "    - 'off'\n",
      "    - stop\n",
      "    - go\n",
      "    - unknown\n",
      "    - silence\n",
      "    batch_size: 128\n",
      "    shuffle: true\n",
      "    augmentor:\n",
      "      shift:\n",
      "        prob: 1.0\n",
      "        min_shift_ms: -5.0\n",
      "        max_shift_ms: 5.0\n",
      "      white_noise:\n",
      "        prob: 1.0\n",
      "        min_level: -90\n",
      "        max_level: -46\n",
      "    num_workers: 12\n",
      "    \n",
      "[NeMo W 2021-03-25 03:26:17 modelPT:140] Please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /media/smajumdar/data/Datasets/GSC_subset/google_speech_recognition_v2/validation_manifest.json\n",
      "    - /media/smajumdar/data/Datasets/GSC_subset/google_speech_recognition_v2/test_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - 'yes'\n",
      "    - 'no'\n",
      "    - up\n",
      "    - down\n",
      "    - left\n",
      "    - right\n",
      "    - 'on'\n",
      "    - 'off'\n",
      "    - stop\n",
      "    - go\n",
      "    - unknown\n",
      "    - silence\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    val_loss_idx: 0\n",
      "    num_workers: 12\n",
      "    \n",
      "[NeMo W 2021-03-25 03:26:17 modelPT:147] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /media/smajumdar/data/Datasets/GSC_subset/google_speech_recognition_v2/validation_manifest.json\n",
      "    - /media/smajumdar/data/Datasets/GSC_subset/google_speech_recognition_v2/test_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - 'yes'\n",
      "    - 'no'\n",
      "    - up\n",
      "    - down\n",
      "    - left\n",
      "    - right\n",
      "    - 'on'\n",
      "    - 'off'\n",
      "    - stop\n",
      "    - go\n",
      "    - unknown\n",
      "    - silence\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    test_loss_idx: 0\n",
      "    num_workers: 12\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-03-25 03:26:17 modelPT:376] Model EncDecClassificationModel was successfully restored from /home/cjbayron/.cache/torch/NeMo/NeMo_1.0.0rc2/MatchboxNet-3x1x64-v2-subset-task/da747cb40572af6f3774d7e33841815c/MatchboxNet-3x1x64-v2-subset-task.nemo.\n"
     ]
    }
   ],
   "source": [
    "#mbn_model = nemo_asr.models.EncDecClassificationModel.from_pretrained(\"MatchboxNet-3x1x64-v2\")\n",
    "mbn_model = nemo_asr.models.EncDecClassificationModel.from_pretrained(\"MatchboxNet-3x1x64-v2-subset-task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304K\t/home/cjbayron/.cache/torch/NeMo/NeMo_1.0.0rc2/MatchboxNet-3x1x64-v2-subset-task/da747cb40572af6f3774d7e33841815c/MatchboxNet-3x1x64-v2-subset-task.nemo\r\n"
     ]
    }
   ],
   "source": [
    "!du -h /home/cjbayron/.cache/torch/NeMo/NeMo_1.0.0rc2/MatchboxNet-3x1x64-v2-subset-task/da747cb40572af6f3774d7e33841815c/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncDecClassificationModel(\n",
       "  (spec_augmentation): SpectrogramAugmentation(\n",
       "    (spec_cutout): SpecCutout()\n",
       "    (spec_augment): SpecAugment()\n",
       "  )\n",
       "  (crop_or_pad): CropOrPadSpectrogramAugmentation()\n",
       "  (preprocessor): AudioToMFCCPreprocessor(\n",
       "    (featurizer): MFCC(\n",
       "      (amplitude_to_DB): AmplitudeToDB()\n",
       "      (MelSpectrogram): MelSpectrogram(\n",
       "        (spectrogram): Spectrogram()\n",
       "        (mel_scale): MelScale()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): ConvASREncoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): JasperBlock(\n",
       "        (mconv): ModuleList(\n",
       "          (0): MaskedConv1d(\n",
       "            (conv): Conv1d(64, 64, kernel_size=[11], stride=[1], padding=(5,), dilation=[1], groups=64, bias=False)\n",
       "          )\n",
       "          (1): MaskedConv1d(\n",
       "            (conv): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm1d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (mout): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): JasperBlock(\n",
       "        (mconv): ModuleList(\n",
       "          (0): MaskedConv1d(\n",
       "            (conv): Conv1d(128, 128, kernel_size=[13], stride=[1], padding=(6,), dilation=[1], groups=128, bias=False)\n",
       "          )\n",
       "          (1): MaskedConv1d(\n",
       "            (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (res): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): MaskedConv1d(\n",
       "              (conv): Conv1d(128, 64, kernel_size=(1,), stride=[1], bias=False)\n",
       "            )\n",
       "            (1): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (mout): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): JasperBlock(\n",
       "        (mconv): ModuleList(\n",
       "          (0): MaskedConv1d(\n",
       "            (conv): Conv1d(64, 64, kernel_size=[15], stride=[1], padding=(7,), dilation=[1], groups=64, bias=False)\n",
       "          )\n",
       "          (1): MaskedConv1d(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (res): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): MaskedConv1d(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(1,), stride=[1], bias=False)\n",
       "            )\n",
       "            (1): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (mout): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): JasperBlock(\n",
       "        (mconv): ModuleList(\n",
       "          (0): MaskedConv1d(\n",
       "            (conv): Conv1d(64, 64, kernel_size=[17], stride=[1], padding=(8,), dilation=[1], groups=64, bias=False)\n",
       "          )\n",
       "          (1): MaskedConv1d(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (res): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): MaskedConv1d(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(1,), stride=[1], bias=False)\n",
       "            )\n",
       "            (1): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (mout): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): JasperBlock(\n",
       "        (mconv): ModuleList(\n",
       "          (0): MaskedConv1d(\n",
       "            (conv): Conv1d(64, 64, kernel_size=[29], stride=[1], padding=(28,), dilation=[2], groups=64, bias=False)\n",
       "          )\n",
       "          (1): MaskedConv1d(\n",
       "            (conv): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm1d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (mout): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): JasperBlock(\n",
       "        (mconv): ModuleList(\n",
       "          (0): MaskedConv1d(\n",
       "            (conv): Conv1d(128, 128, kernel_size=[1], stride=[1], dilation=[1], bias=False)\n",
       "          )\n",
       "          (1): BatchNorm1d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (mout): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ConvASRDecoderClassification(\n",
       "    (pooling): AdaptiveAvgPool1d(output_size=1)\n",
       "    (decoder_layers): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=12, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (loss): CrossEntropyLoss()\n",
       "  (_accuracy): TopKClassificationAccuracy()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0271, -0.3415, -0.2635,  ...,  0.4301, -0.0387, -0.3152],\n",
      "        [-0.0592,  0.1672,  0.8944,  ...,  0.4101, -0.0634, -0.2409],\n",
      "        [-0.0984, -0.1541, -0.1755,  ..., -0.1018,  0.4224, -0.3147],\n",
      "        ...,\n",
      "        [ 0.1432,  0.6111, -0.4245,  ..., -0.1463, -0.3457,  0.0450],\n",
      "        [ 0.3348,  0.7647,  0.1555,  ...,  0.3096, -0.4508,  0.4696],\n",
      "        [-0.0530, -0.1530, -0.0728,  ..., -0.1274, -0.2428, -0.1959]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.6165, -0.3133,  0.9215,  0.0745,  0.3984, -0.2405,  0.0378,  0.3498,\n",
      "         0.0644,  0.0400,  0.1372, -0.8501], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in mbn_model.decoder.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all params\n",
    "for param in mbn_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# unfreeze decoder\n",
    "for param in mbn_model.decoder.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder.decoder_layers.0.weight\n",
      "decoder.decoder_layers.0.bias\n"
     ]
    }
   ],
   "source": [
    "# check layers to train\n",
    "for param in mbn_model.named_parameters():\n",
    "    if param[1].requires_grad:\n",
    "        print(param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check: https://towardsdatascience.com/train-conversational-ai-in-3-lines-of-code-with-nemo-and-lightning-a6088988ae37"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
